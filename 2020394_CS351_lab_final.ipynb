{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ba1173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db72ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Permalink</th>\n",
       "      <th>User</th>\n",
       "      <th>Outlinks</th>\n",
       "      <th>CountLinks</th>\n",
       "      <th>ReplyCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>ConversationId</th>\n",
       "      <th>Language</th>\n",
       "      <th>Source</th>\n",
       "      <th>Media</th>\n",
       "      <th>QuotedTweet</th>\n",
       "      <th>MentionedUsers</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>hastag_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-22 13:44:34+00:00</td>\n",
       "      <td>1617156270871689984</td>\n",
       "      <td>ChatGPTã§éŠã¶ã®å¿˜ã‚Œã¦ãŸï¼ï¼\\næ›¸é¡žä...</td>\n",
       "      <td>mochico0123</td>\n",
       "      <td>https://twitter.com/mochico0123/status/1617156...</td>\n",
       "      <td>https://twitter.com/mochico0123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1617156270871689984</td>\n",
       "      <td>ja</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-22 13:44:39+00:00</td>\n",
       "      <td>1617156291046129920</td>\n",
       "      <td>@AlexandrovnaIng Prohibition of ChatGPT has be...</td>\n",
       "      <td>Caput_LupinumSG</td>\n",
       "      <td>https://twitter.com/Caput_LupinumSG/status/161...</td>\n",
       "      <td>https://twitter.com/Caput_LupinumSG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1617148639993799936</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[User(username='AlexandrovnaIng', id=282705900...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-22 13:44:44+00:00</td>\n",
       "      <td>1617156308926340096</td>\n",
       "      <td>Schaut Euch an, was @fobizz @DianaKnodel alles...</td>\n",
       "      <td>ciffi</td>\n",
       "      <td>https://twitter.com/ciffi/status/1617156308926...</td>\n",
       "      <td>https://twitter.com/ciffi</td>\n",
       "      <td>['https://us02web.zoom.us/webinar/register/801...</td>\n",
       "      <td>['https://t.co/DsoeVJrPBp', 'https://t.co/HflT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1617156308926340096</td>\n",
       "      <td>de</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
       "      <td>[Photo(previewUrl='https://pbs.twimg.com/media...</td>\n",
       "      <td>https://twitter.com/DianaKnodel/status/1617153...</td>\n",
       "      <td>[User(username='fobizz', id=884708145792253952...</td>\n",
       "      <td>['#ChatGPT']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-22 13:44:49+00:00</td>\n",
       "      <td>1617156332297250048</td>\n",
       "      <td>Bow down to chatGPT ðŸ«¡..... https://t.co/ENT...</td>\n",
       "      <td>Vishwasrisiri</td>\n",
       "      <td>https://twitter.com/Vishwasrisiri/status/16171...</td>\n",
       "      <td>https://twitter.com/Vishwasrisiri</td>\n",
       "      <td>['https://twitter.com/agadmator/status/1617155...</td>\n",
       "      <td>['https://t.co/ENTSzi2AQ9']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1617156332297250048</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/agadmator/status/161715501...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-22 13:44:52+00:00</td>\n",
       "      <td>1617156345064570112</td>\n",
       "      <td>Profilinde vatan, TÃ¼rkiye falan yazan bireyle...</td>\n",
       "      <td>0xGenetikciniz</td>\n",
       "      <td>https://twitter.com/0xGenetikciniz/status/1617...</td>\n",
       "      <td>https://twitter.com/0xGenetikciniz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1617156345064570112</td>\n",
       "      <td>tr</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime             Tweet Id  \\\n",
       "0  2023-01-22 13:44:34+00:00  1617156270871689984   \n",
       "1  2023-01-22 13:44:39+00:00  1617156291046129920   \n",
       "2  2023-01-22 13:44:44+00:00  1617156308926340096   \n",
       "3  2023-01-22 13:44:49+00:00  1617156332297250048   \n",
       "4  2023-01-22 13:44:52+00:00  1617156345064570112   \n",
       "\n",
       "                                                Text         Username  \\\n",
       "0  ChatGPTã§éŠã¶ã®å¿˜ã‚Œã¦ãŸï¼ï¼\\næ›¸é¡žä...      mochico0123   \n",
       "1  @AlexandrovnaIng Prohibition of ChatGPT has be...  Caput_LupinumSG   \n",
       "2  Schaut Euch an, was @fobizz @DianaKnodel alles...            ciffi   \n",
       "3  Bow down to chatGPT ðŸ«¡..... https://t.co/ENT...    Vishwasrisiri   \n",
       "4  Profilinde vatan, TÃ¼rkiye falan yazan bireyle...   0xGenetikciniz   \n",
       "\n",
       "                                           Permalink  \\\n",
       "0  https://twitter.com/mochico0123/status/1617156...   \n",
       "1  https://twitter.com/Caput_LupinumSG/status/161...   \n",
       "2  https://twitter.com/ciffi/status/1617156308926...   \n",
       "3  https://twitter.com/Vishwasrisiri/status/16171...   \n",
       "4  https://twitter.com/0xGenetikciniz/status/1617...   \n",
       "\n",
       "                                  User  \\\n",
       "0      https://twitter.com/mochico0123   \n",
       "1  https://twitter.com/Caput_LupinumSG   \n",
       "2            https://twitter.com/ciffi   \n",
       "3    https://twitter.com/Vishwasrisiri   \n",
       "4   https://twitter.com/0xGenetikciniz   \n",
       "\n",
       "                                            Outlinks  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  ['https://us02web.zoom.us/webinar/register/801...   \n",
       "3  ['https://twitter.com/agadmator/status/1617155...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                          CountLinks  ReplyCount  \\\n",
       "0                                                NaN           1   \n",
       "1                                                NaN           1   \n",
       "2  ['https://t.co/DsoeVJrPBp', 'https://t.co/HflT...           0   \n",
       "3                        ['https://t.co/ENTSzi2AQ9']           0   \n",
       "4                                                NaN           0   \n",
       "\n",
       "   RetweetCount  LikeCount  QuoteCount       ConversationId Language  \\\n",
       "0             0          5           0  1617156270871689984       ja   \n",
       "1             0          5           0  1617148639993799936       en   \n",
       "2             0          4           0  1617156308926340096       de   \n",
       "3             0          2           0  1617156332297250048       en   \n",
       "4             0          4           0  1617156345064570112       tr   \n",
       "\n",
       "                                              Source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com/#!/download/ipad\" ...   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                               Media  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  [Photo(previewUrl='https://pbs.twimg.com/media...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         QuotedTweet  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  https://twitter.com/DianaKnodel/status/1617153...   \n",
       "3  https://twitter.com/agadmator/status/161715501...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                      MentionedUsers       hashtag  \\\n",
       "0                                                NaN            []   \n",
       "1  [User(username='AlexandrovnaIng', id=282705900...            []   \n",
       "2  [User(username='fobizz', id=884708145792253952...  ['#ChatGPT']   \n",
       "3                                                NaN            []   \n",
       "4                                                NaN            []   \n",
       "\n",
       "   hastag_counts  \n",
       "0              0  \n",
       "1              0  \n",
       "2              1  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data=pd.read_excel('/Users/student/Downloads/chatgpt1.xlsx')\n",
    "chat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48bef4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset into a Pandas DataFrame\n",
    "data = pd.read_excel('/Users/student/Downloads/chatgpt1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f90fe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (35, 20)\n",
      "Testing set shape: (9, 20)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_excel('/Users/student/Downloads/chatgpt1.xlsx')\n",
    "\n",
    "\n",
    "data = data.dropna() \n",
    "\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", train_data.shape)\n",
    "print(\"Testing set shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af9402e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape (features): (40000,)\n",
      "Testing set shape (features): (10001,)\n",
      "Training set shape (target): (40000,)\n",
      "Testing set shape (target): (10001,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_excel('/Users/student/Downloads/chatgpt1.xlsx')\n",
    "\n",
    "features = data['Text']  \n",
    "target = data['Language'] \n",
    "\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set shape (features):\", features_train.shape)\n",
    "print(\"Testing set shape (features):\", features_test.shape)\n",
    "print(\"Training set shape (target):\", target_train.shape)\n",
    "print(\"Testing set shape (target):\", target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91349e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#following is the code for sentiment analysis \n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load the Excel sheet into a pandas DataFrame\n",
    "df = pd.read_excel('/Users/student/Downloads/chatgpt1.xlsx')  # Replace 'data.xlsx' with your file path\n",
    "\n",
    "# Perform sentiment analysis on each row\n",
    "sentiments = []\n",
    "for index, row in df.iterrows():\n",
    "    text = row['Text']  # Replace 'Text' with the column name containing the text data\n",
    "    blob = TextBlob(text)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    sentiments.append(sentiment)\n",
    "\n",
    "# Add the sentiment scores to the DataFrame\n",
    "df['Sentiment'] = sentiments\n",
    "\n",
    "# Display the results\n",
    "for index, row in df.iterrows():\n",
    "    text = row['Text']  # Replace 'Text' with the column name containing the text data\n",
    "    sentiment = row['Sentiment']\n",
    "    if sentiment > 0:\n",
    "        print(f'Text: \"{text}\"\\nSentiment: Positive\\n')\n",
    "    elif sentiment < 0:\n",
    "        print(f'Text: \"{text}\"\\nSentiment: Negative\\n')\n",
    "    else:\n",
    "        print(f'Text: \"{text}\"\\nSentiment: Neutral\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ec0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#following is the code for user classification\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the data from an Excel sheet into a pandas DataFrame\n",
    "df = pd.read_excel('/Users/student/Downloads/chatgpt1.xlsx')  # Replace 'data.xlsx' with your file path\n",
    "\n",
    "# Preprocess the text data\n",
    "# Assuming the 'Text' column contains the tweet text and 'UserID' column contains the user ID\n",
    "preprocessed_data = df['Text'].apply(lambda x: x.lower())  # Convert text to lowercase\n",
    "labels = df['UserID']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data to numerical features using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#following is the code for clustering \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load the data from an Excel sheet into a pandas DataFrame\n",
    "df = pd.read_excel('/Users/student/Downloads/chatgpt1.xlsx')  # Replace 'data.xlsx' with your file path\n",
    "\n",
    "# Preprocess the text data\n",
    "# Assuming the 'Text' column contains the tweet text\n",
    "preprocessed_data = df['Text'].apply(lambda x: x.lower())  # Convert text to lowercase\n",
    "\n",
    "# Convert text data to numerical features using TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(preprocessed_data)\n",
    "\n",
    "# Perform K-means clustering\n",
    "num_clusters = 5  # Set the number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Get the cluster labels for each tweet\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Evaluate the clustering using silhouette score\n",
    "silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "print(\"Silhouette Score:\", silhouette_avg)\n",
    "\n",
    "# Add the cluster labels to the DataFrame\n",
    "df['Cluster'] = cluster_labels\n",
    "\n",
    "# Optional: Save the DataFrame with cluster labels to a new Excel file\n",
    "df.to_excel('tweet_clusters.xlsx', index=False)  # Replace 'tweet_clusters.xlsx' with your desired output file name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32167695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "data = pd.read_excel('/Users/student/Downloads/chatgpt1.xlsx')\n",
    "\n",
    "features = data['Text'] \n",
    "target = data['Language']  \n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "\n",
    "features_test_transformed = vectorizer.transform(features_test)\n",
    "print(\"Training features shape (transformed):\", features_train_transformed.shape)\n",
    "print(\"Testing features shape (transformed):\", features_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c194bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for engagemnt perdiction\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the data from an Excel sheet into a pandas DataFrame\n",
    "df = pd.read_excel('/Users/student/Downloads/chatgpt1.xlsx')  # Replace 'data.xlsx' with your file path\n",
    "\n",
    "# Preprocess the text data\n",
    "# Assuming the 'Text' column contains the tweet text\n",
    "preprocessed_data = df['Text'].apply(lambda x: x.lower())  # Convert text to lowercase\n",
    "\n",
    "# Convert text data to numerical features using TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_text = vectorizer.fit_transform(preprocessed_data)\n",
    "\n",
    "# Extract other features\n",
    "X_other = df['HashtagCount'].values.reshape(-1, 1)  # Assuming 'HashtagCount' is the column with hashtag counts\n",
    "\n",
    "# Combine text and other features\n",
    "X = pd.concat([pd.DataFrame(X_text.toarray()), pd.DataFrame(X_other)], axis=1)\n",
    "\n",
    "# Perform K-means clustering\n",
    "num_clusters = 5  # Set the number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Get the cluster labels for each tweet\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Add the cluster labels to the DataFrame\n",
    "df['Cluster'] = cluster_labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "y_retweets = df['Retweets']  # Assuming 'Retweets' is the column with retweet counts\n",
    "y_likes = df['Likes']  # Assuming 'Likes' is the column with like counts\n",
    "X_train, X_test, y_retweets_train, y_retweets_test, y_likes_train, y_likes_test = train_test_split(\n",
    "    X, y_retweets, y_likes, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train a linear regression model for retweets\n",
    "reg_retweets = LinearRegression()\n",
    "reg_retweets.fit(X_train, y_retweets_train)\n",
    "\n",
    "# Make predictions for retweets\n",
    "y_retweets_pred = reg_retweets.predict(X_test)\n",
    "\n",
    "# Evaluate the model for retweets\n",
    "mse_retweets = mean_squared_error(y_retweets_test, y_retweets_pred)\n",
    "r2_retweets = r2_score(y_retweets_test, y_retweets_pred)\n",
    "print(\"Retweets - Mean Squared Error:\", mse_retweets)\n",
    "print(\"Retweets - R2 Score:\", r2_retweets)\n",
    "\n",
    "# Train a linear regression model for likes\n",
    "reg_likes = LinearRegression()\n",
    "reg_likes.fit(X_train, y_likes_train)\n",
    "\n",
    "# Make predictions for likes\n",
    "y_likes_pred = reg_likes.predict(X_test)\n",
    "\n",
    "# Evaluate the model for likes\n",
    "mse_likes = mean_squared_error(y_likes_test, y_likes_pred)\n",
    "r2_likes = r2_score(y_likes_test, y_likes_pred)\n",
    "print(\"Likes - Mean Squared Error:\", mse_likes)\n",
    "print(\"Likes - R2 Score:\", r2_likes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c2ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following is the code for hashtag analysis \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load the data from an Excel sheet into a pandas DataFrame\n",
    "df = pd.read_excel('/Users/student/Downloads/chatgpt1.xlsx')  # Replace 'data.xlsx' with your file path\n",
    "\n",
    "# Preprocess the text data and extract hashtags\n",
    "# Assuming the 'Text' column contains the tweet text\n",
    "preprocessed_data = df['Text'].apply(lambda x: x.lower())  # Convert text to lowercase\n",
    "hashtags = df['Hashtags'].str.lower()  # Assuming 'Hashtags' is the column with hashtags\n",
    "\n",
    "# Convert text data to numerical features using TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_text = vectorizer.fit_transform(preprocessed_data)\n",
    "\n",
    "# Perform K-means clustering on hashtag frequency\n",
    "num_clusters = 5  # Set the number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(X_text)\n",
    "\n",
    "# Get the cluster labels for each tweet\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Add the cluster labels to the DataFrame\n",
    "df['Cluster'] = cluster_labels\n",
    "\n",
    "# Create a frequency table of hashtags\n",
    "frequency_table = hashtags.str.split().explode().value_counts().reset_index()\n",
    "frequency_table.columns = ['Hashtag', 'Frequency']\n",
    "\n",
    "# Perform K-means clustering on hashtag co-occurrence\n",
    "cooccurrence_vectorizer = TfidfVectorizer(token_pattern=r'#\\w+')\n",
    "X_cooccurrence = cooccurrence_vectorizer.fit_transform(hashtags)\n",
    "kmeans_cooccurrence = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans_cooccurrence.fit(X_cooccurrence)\n",
    "\n",
    "# Get the cluster labels for each hashtag\n",
    "hashtag_cluster_labels = kmeans_cooccurrence.labels_\n",
    "\n",
    "# Add the cluster labels to the frequency table\n",
    "frequency_table['Cluster'] = hashtag_cluster_labels\n",
    "\n",
    "# Print the frequency table\n",
    "print(\"Hashtag Frequency Table:\")\n",
    "print(frequency_table)\n",
    "\n",
    "# Optional: Save the frequency table to a new Excel file\n",
    "frequency_table.to_excel('hashtag_frequency.xlsx', index=False)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
